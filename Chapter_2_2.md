# 2.2 RAG 與環境上下文：不僅是回訊，而是為 Agent 準備精確的決策邊界

在 2.1 中，我們將企業數據轉化成了「知識資產」。然而，擁有圖書館並不代表能自動解決問題。**RAG (Retrieval-Augmented Generation，檢索增強生成)** 技術的出現，就是為了在大型語言模型 (LLM) 與企業知識庫之間，搭建一座即時、動態、且精確的橋樑。

對於企業級應用而言，RAG 的關鍵不在於「搜尋」，而在於為 AI 代理人提供精確的**「環境上下文 (Environmental Context)」**。

### 從「問答機器人」到「具備知識邊界的代理人」
早期的企業 AI 導入多半停留在「問答」。但當我們進入 Agentic AI 時代，RAG 的角色發生了質變：它不再只是為了回覆讀者的提問，而是為了告訴代理人：「在目前的組織規則下，你被授權做到什麼程度？」以及「執行這項任務時，必須遵守哪些邊界條件？」

例如，一個負責「採購談判」的 Agent，它需要的環境上下文包括：
1. **歷史數據**：過去三年與該供應商的成交價格。
2. **規則限制**：公司最新的財務報銷準則與合規要求。
3. **動態知識**：當前的全球供應鏈波動報告。

### 強化版 RAG 的核心機制 (Advanced RAG)
要讓 RAG 真正支撐起企業級應用，單純的關鍵字匹配是不夠的。我們必須引入以下進階機制：

- **混合檢索 (Hybrid Search)**：
  結合「向量搜索（抓取語義）」與「關鍵字搜索（抓取特定產品序號或法規術語）」。這能確保 AI 既能理解使用者的意圖，又不會在精確的術語上出錯。
- **重排序 (Re-ranking)**：
  檢索系統可能會找回 10 條看似相關的知識塊，但 AI 的上下文長度有限。透過「重排序模型」，讓最關鍵、最有證據價值的知識出現在最前面。
- **上下文注入與 Prompt 的結構化**：
  如何將檢索到的知識「餵」給 AI？我們必須設計精密的系統提示詞 (System Prompt)，告訴 AI：「以下是從公司知識庫檢索出來的真實依據，請僅根據這些內容回答，嚴禁發揮想像。」

### 決策邊界的重要性：防止幻覺 (Anti-Hallucination)
企業導入 AI 最怕模型「一本正經地胡說八道」。RAG 是目前解決幻覺問題最有效的藥方。透過 RAG，我們將 AI 的角色從「全知全能的學者」限制為**「翻閱開卷考題的監考官」**。

如果 RAG 檢索不到對應的資訊，系統應該被設定為輸出：「抱歉，我在現有的企業文件夾中找不到相關資訊，請聯繫人力資源部。」這種「承認無知」的能力，才是企業級 AI 真正可靠的標誌。

### RAG 到 Agentic AI 的跨越
當 RAG 整合進 Agentic 工作流時，Agent 可以發啟動多次檢索：
1. **第一步檢索**：了解任務目標。
2. **第二步檢索**：尋找達成目標所需的工具說明。
3. **第三步檢索**：確認執行結果是否符合公司安全性規範。

### 結論
RAG 是讓模型具備「現代理智」的關鍵。沒有 RAG 的 AI 只是在複誦訓練時死背的舊知識；擁有高品質 RAG 架構的 AI，才是能跟隨企業每天同步更新、動態決策的強大盟友。

在下一節 2.3 中，我們將探討這套架構背後的安全鎖：如何確保獲取的知識是被授權的。
